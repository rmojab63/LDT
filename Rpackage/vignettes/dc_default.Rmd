---
title: "DC: Loan default prediction"
output: rmarkdown::html_vignette
bibliography: ldt.bib
vignette: >
  %\VignetteIndexEntry{DC: Loan default prediction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
ec <- FALSE # identical(Sys.getenv("NOT_CRAN", unset = "true"), "true")
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "  >",
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  results = "hide",
  eval = ec
)
```

```{r setup}
library(ldt)
library(kableExtra)
```

 
```{r eval_warn, eval=TRUE, echo=FALSE, results='asis'}
if (ec == FALSE){
  cat("\n---------------------\n     Warning: no evaluation\n---------------------\n\n")
}
```

```{r}
if (dir.exists("data") == FALSE)
  dir.create("data")
```

It is recommended to read the following vignettes first:

- [SUR: Determinants of long-run economic growth](sur_growth.html)
- [SUR: A simulation](sur_simulation.html)

## Introduction

In **ldt**, we _automatically explain_ or _automatically predict_ one or more than one random variable. In this vignette, we design a model set for predicting loan default. Of course, we focus on comparing the performance of _logit_ and _probit_ models. We use AUC as a performance measure:

```{r dc_measure_options}
measureOptions <- GetMeasureOptions(
  typesIn = c("aucIn", "costMatrixIn"),
  typesOut = c("aucOut", "costMatrixOut")
)
```

Note that, we calculate both in-sample and out-of-sample AUC. Also, we calculate the error ratio by using the following cost matrix:

\begin{equation}
\label{eq:error-ratio}
\begin{bmatrix}
0.5 & 1 & 1\\
1.0 & 0 & 0
\end{bmatrix}
\end{equation}

which is:

```{r cost_matrix}
costMatrix <- matrix(c(0.5, 1, 1, 0, 1, 0), 2, 3)
```

Note that this is not a favorable cost matrix in an actual application. One might want to define more thresholds or increase the costs in the third column. 

<p style="margin-left:40px;">
What is a cost matrix in **ldt**? The general form of a cost matrix in binary case is:
\begin{equation}
\begin{bmatrix}
t_1 & c_{11} & c_{12}\\
t_2 & c_{21} & c_{22}\\
\vdots & \vdots&\vdots\\
t_n & c_{n1} & c_{n2}\\
\end{bmatrix}
\end{equation}
In this presentation, $t_i$ for $i=1,\ldots,n$ is the threshold for the predicted probability. If the actual value is negative (i.e., $y_i=0$), the cost is determined by the first column. Otherwise (i.e., $y_i=1$), the cost is determined by the third column.
</p>


## Data
In this vignette, we use @dataset_berka data-set and `ldt::Data_BerkaLoan()` function to get a sample for the dependent variable and the potential predictors (or, features):

```{r data_get}
berkadata <- tryCatch(readRDS("data/dc_berka_data.RData"), error = function(e) NULL)
if (is.null(berkadata)) {
  berka1 <- Data_BerkaLoan(positive = c("B", "D"), negative = c("A", "C"))
  berka2 <- Data_BerkaLoan(positive = c("B"), negative = c("A"))
  berkadata <- list(berka1 = berka1, berka2 = berka2)
  saveRDS(berkadata, file = "data/dc_berka_data.RData")
}
data <- berkadata$berka1
```

The data set has a _loan table_ with 682 observations, each labeled as one of the following: 

- A: finished (`r if (ec) round(sum(data$status=="A")/length(data$status)*100,1) else NA`\%);
- B: finished with default (`r if (ec) round(sum(data$status=="B")/length(data$status)*100,1) else NA`\%);
- C: running (`r if (ec) round(sum(data$status=="C")/length(data$status)*100,1) else NA`\%); and
- D: running with default (`r if (ec) round(sum(data$status=="D")/length(data$status)*100,1) else NA`\%).

Numbers in the parenthesis show the percentage of data in each class. Each loan observation has an _account identification_ that can provide other types of information from other tables, such as the characteristics of the account of the loan and its transactions. Furthermore, each account has a _district identification_ that can provide information about the demographic characteristics of the location of its branch.  The combined table has `r ncol(data)-2` features (including the label) and `r nrow(data)` observations. 

For this example, both _finished_ and _running_ (without default) classes are considered to be _negative_ and both finished and running _with default_ classes to be positive observations. Note that the observations labeled _running_ might introduce measurement errors. Without them, the length of the table is `r if (ec) nrow(berkadata$berka2) else NA`. If you do not want to use this part of the data, use `data <- berkadata$berka2` in the previous chunk of code.

The dependent and potential exogenous variables are:

```{r data_define}
y <- data[, c("label"), drop = FALSE]
x <- data[, 4:length(data)]
```

Note that the first 2 columns of `data` are `id` and `status`. Since only `r if (ec) (sum(y==1)/nrow(y))*200 else NA`\% of the observations are positive, we define and use the following weight vector to balance the data:  

```{r }
weight <- as.numeric((y == 1) * (nrow(y) / sum(y == 1)) + (y == 0))
```

## Estimation 

There are `r if (ec) ncol(x) else NA` potential predictors and the size of the potential predicting models is relatively large. We follow a step-wise search approach by defining the following two arguments for the `DcSearch_s()` function:

```{r modelset_steps}
xSizes <- list(c(1, 2), c(3, 4, 5))
xCounts <- c(NA, 20)
```

We also need a seed for the RNG and some other options to define the out-of-sample prediction:

```{r seed}
measureOptions$seed <- 340
measureOptions$simFixSize <- 50
measureOptions$trainRatio <- 0.75
```

Note that the out-of-sample simulation depends on random sampling. Finally, we start the search function:

```{r dc_estimate}
berka_res <- list(
  logit = DcSearch_s(
    x = x, y = y, w = weight, costMatrices = list(costMatrix),
    xSizes = xSizes, counts = xCounts,
    searchLogit = TRUE, searchProbit = FALSE,
    searchItems = GetSearchItems(bestK = 20, inclusion = TRUE),
    measureOptions = measureOptions,
    searchOptions = GetSearchOptions(printMsg = TRUE),
    savePre = "data/dc_berka_logit_"
  ),
  probit = DcSearch_s(
    x = x, y = y, w = weight, costMatrices = list(costMatrix),
    xSizes = xSizes, counts = xCounts,
    searchLogit = FALSE, searchProbit = TRUE,
    searchItems = GetSearchItems(bestK = 20, inclusion = TRUE),
    measureOptions = measureOptions,
    searchOptions = GetSearchOptions(printMsg = TRUE),
    savePre = "data/dc_berka_probit_"
  )
)
```

Since we want to compare the performance of logit and probit models, we run two discrete choice searches. All options are similar, but one is with `searchLogit = TRUE` and the other is with `searchLogit = FALSE` and `searchProbit = TRUE`. The results are reported in the following plot:

```{r plot_logit_probit, echo=FALSE, results='hide', fig.show='hold', fig.cap='Comparing the performance of best logit model and best probit model (cost-matrix and AUC)', out.width='45%'}
op <- par(cex = 0.6)
data_cost <- data.frame(
  cost_in = c(
    berka_res$logit$costMatrixIn$target1$model$bests$best1$weight,
    berka_res$probit$costMatrixOut$target1$model$bests$best1$weight
  ),
  cost_out = c(
    berka_res$logit$costMatrixIn$target1$model$bests$best1$weight,
    berka_res$probit$costMatrixIn$target1$model$bests$best1$weight
  )
)

data_auc <- data.frame(
  auc_in = c(
    berka_res$logit$aucIn$target1$model$bests$best1$weight,
    berka_res$probit$aucIn$target1$model$bests$best1$weight
  ),
  auc_out = c(
    berka_res$logit$aucOut$target1$model$bests$best1$weight,
    berka_res$probit$aucOut$target1$model$bests$best1$weight
  )
)
rns <- c("Logit", "Probit")
cns <- c("In-Sample", "Out-Of-Sample")
rownames(data_cost) <- rns
rownames(data_auc) <- rns
colnames(data_cost) <- cns
colnames(data_auc) <- cns


angle <- c(0, 45)
density <- 20
col <- c("black", "red")
lwd <- 1

barplot(as.matrix(data_cost),
  beside = T, ylim = c(0, 1),
  col = col, lwd = lwd, angle = angle, density = density
)
legend("top",
  legend = colnames(data_cost), angle = angle, density = density,
  fill = col, bg = NULL
)

barplot(as.matrix(data_auc),
  beside = T, ylim = c(0, 1),
  col = col, lwd = lwd, angle = angle, density = density
)
legend("top",
  legend = colnames(data_auc), angle = angle, density = density,
  fill = col, bg = NULL
)
```



## References


